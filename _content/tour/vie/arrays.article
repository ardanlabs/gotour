Mảng (Arrays)
Mảng là 1 cấu trúc dữ liệu đặc biệt của Go cho phép ta cấp phát các khối bộ nhớ có kích thước cố định liên tục nhau.

* Mảng (Arrays)

- [[https://www.ardanlabs.com/training/individual-on-demand/ultimate-go-bundle/][Xem Video]]
- Cần hỗ trợ Học phí, hãy sử dụng [[https://www.ardanlabs.com/scholarship/][Đơn xin Học bổng]] 
của chúng tôi.

Mảng là một cấu trúc dữ liệu đặc biệt của Go cho phép chúng ta cấp phát các khối bộ nhớ có kích 
thước cố định liên tục nhau.
Mảng có một số tính năng đặc biệt trong Go liên quan đến cách chúng được khai báo và phân loại.

** Code Review

- *Ví* *dụ* *1:* Khai báo, khởi tạo và duyệt mảng
- *Ví* *dụ* *2:* Những loại mảng khác nhau
- *Ví* *dụ* *3:* Cấp phát bộ nhớ liên tục
- *Ví* *dụ* *4:* Cơ chế lặp với `range`

.play arrays/vidu1.go
.play arrays/vidu2.go
.play arrays/vidu3.go
.play arrays/vidu4.go

** Khai báo và khởi tạo giá trị

Khai báo một mảng gồm 5 chuỗi (string) với giá trị khởi tạo là 0.

    var strings [5]string

Một chuỗi là một cấu trúc dữ liệu không thể thay đổi, có 2 phần, đại diện cho một con trỏ đến 
một mảng `byte` và độ dài của mảng đó.
Vì mảng này được đặt ở trạng thái zero value (giá trị 0), mỗi phần tử được đặt ở trạng thái 
zero value của nó.
Điều này có nghĩa là mỗi chuỗi có phần đầu tiên (con trỏ) là `nil` và phần thứ hai (độ dài) là 0.

    strings[0] = "Apple"
    strings[1] = "Orange"
    strings[2] = "Banana"
    strings[3] = "Grape"
    strings[4] = "Plum"

.image /tour/eng/static/img/a1.png

** Gán giá trị cho chuỗi

Điều gì xảy ra khi một chuỗi được gán cho một chuỗi khác?

    strings[0] = "Apple"

Khi một chuỗi được gán cho một chuỗi khác, giá trị của hai phần (con trỏ và độ dài) trong chuỗi 
được sao chép, kết quả là hai chuỗi khác nhau cùng chia sẻ một mảng bên dưới.

.image /tour/eng/static/img/a2.png

"Chi phí" sao chép 1 chuỗi là như nhau bất kể kích thước của chuỗi, nó chỉ sao chép 2 thứ: 
con trỏ và độ dài mảng bên dưới.

** Duyệt qua các tập hợp

Go cung cấp hai cách khác nhau để duyệt qua một tập hợp.
Chúng ta có thể duyệt bằng cách sử dụng giá trị hoặc con trỏ.

    // duyệt giá trị
    for i, fruit := range strings {
        println(i, fruit)
    }


    // duyệt con trỏ
    for i := range strings {
        println(i, strings[i])
    }

Khi duyệt giá trị, hai điều xảy ra.

- Đầu tiên, tập hợp mà chúng ta đang duyệt qua được sao chép và bản sao được sử dụng để duyệt qua 
  thay vì bản gốc.
  Trong trường hợp của một mảng, bản sao có thể tốn kém vì toàn bộ mảng được sao chép.
  Trong trường hợp của một `slice`, không có chi phí thực sự vì chỉ có thông tin nội bộ của `slice` 
  được sao chép không phải là mảng bên dưới. (Xem phần `slice` để biết thêm chi tiết.)

- Thứ hai, chúng ta nhận được một bản sao của mỗi phần tử được lặp qua.

Khi duyệt con trỏ, chúng ta lặp qua bản gốc và truy cập trực tiếp vào mỗi phần tử trong tập hợp.

** Duyệt giá trị

Cho đoạn code và kết quả bên dưới.

    strings := [5]string{"Apple", "Orange", "Banana", "Grape", "Plum"}
    for i, fruit := range strings {
        println(i, fruit)
    }

Output:

    0 Apple
    1 Orange
    2 Banana
    3 Grape
    4 Plum

Biến `strings` là một mảng gồm 5 chuỗi. Vòng lặp duyệt qua mỗi chuỗi trong tập hợp, hiển thị 
vị trí và giá trị chuỗi. Vì đây là duyệt giá trị, vòng lặp `for` duyệt qua bản sao của mảng 
và trong mỗi lần lặp, biến `fruit` là một bản sao của từng chuỗi trong mảng.

Hãy để ý rằng biến `fruit` được truyền vào hàm `println` sử dụng giá trị.
Hàm `println` đang nhận bản sao riêng của giá trị chuỗi. Sau khi chuỗi được truyền vào hàm 
`println`, có 4 bản sao của giá trị chuỗi (mảng gốc, bản sao của mảng, biến `fruit` và bản sao 
cho hàm `println`). Tất cả 4 bản sao đều chia sẻ cùng một mảng `byte` bên dưới.

.image /tour/eng/static/img/a3.png

Tạo bản sao của giá trị chuỗi là quan trọng vì nó ngăn giá trị chuỗi thoát ra khỏi `heap`.
Điều này loại bỏ việc cấp phát không hiệu quả trên `heap`.

** Duyệt con trỏ

Cho đoạn code và kết quả bên dưới.

    strings := [5]string{"Apple", "Orange", "Banana", "Grape", "Plum"}
    for i := range strings {
        println(i, strings[i])
    }

Output:

    0 Apple
    1 Orange
    2 Banana
    3 Grape
    4 Plum

Một lần nữa, biến `strings` là một mảng gồm 5 chuỗi. Vòng lặp duyệt qua mỗi chuỗi trong tập hợp, 
hiển thị vị trí và giá trị chuỗi.
Vì đây là duyệt con trỏ, vòng lặp `for` duyệt qua mảng `strings` trực tiếp và trong mỗi lần lặp, 
giá trị chuỗi cho mỗi vị trí được truy cập trực tiếp khi gọi hàm `println`.

** Các loại mảng

Bạn sẽ ngạc nhiên khi thấy trình biên dịch (compiler) trả về lỗi khi gán các mảng cùng loại 
nhưng có độ dài khác nhau.

    var five [5]int
    four := [4]int{10, 20, 30, 40}

    five = four

Compiler Error:

    cannot use four (type [4]int) as type [5]int in assignment

Chúng ta khai báo một mảng gồm 5 số nguyên được khởi tạo ở trạng thái zero value của nó. Sau đó 
khai báo 1 mảng gồm 4 số nguyên được khởi tạo với các giá trị khá 0. Khi ta thử gán chúng cho 
nhau thì trình biên dịch báo lỗi, "không thể sử dụng `four` (kiểu `[4]int`) như là 
kiểu `[5]int` trong phép gán".

Hiểu được trình biên dịch đang nói gì là rất quan trọng.
Nó đang nói rằng một mảng gồm 4 số nguyên và một mảng gồm 5 số nguyên đại diện cho các 
kiểu dữ liệu khác nhau.
Kích thước của một mảng là một phần của thông tin của kiểu dữ liệu.
Trong Go thì kích thước của một mảng phải được biết trước khi biên dịch.

** Cấp phát bộ nhớ liên tục

Chúng ta muốn chứng minh rằng một mảng cung cấp một bố cục bộ nhớ liên tục.

    five := [5]string{"Annie", "Betty", "Charley", "Doug", "Bill"}

    for i, v := range five {
        fmt.Printf("Value[%s]\tAddress[%p]  IndexAddr[%p]\n",
            v, &v, &five[i])
    }

Output:

    Value[Annie]     Address[0xc000010250]    IndexAddr[0xc000052180]
    Value[Betty]     Address[0xc000010250]    IndexAddr[0xc000052190]
    Value[Charley]   Address[0xc000010250]    IndexAddr[0xc0000521a0]
    Value[Doug]      Address[0xc000010250]    IndexAddr[0xc0000521b0]
    Value[Bill]      Address[0xc000010250]    IndexAddr[0xc0000521c0]

Chúng ta khai báo một mảng gồm 5 chuỗi được khởi tạo với các giá trị.
Sau đó sử dụng duyệt theo giá trị để hiển thị thông tin về mỗi chuỗi.
Kết quả hiển thị mỗi giá trị chuỗi, địa chỉ của biến `v` và địa chỉ của mỗi phần tử trong mảng.

Bạn có thể thấy mảng là một khối bộ nhớ liên tục và một chuỗi là một cấu trúc dữ liệu gồm hai 
phần hoặc 16 `byte` trên kiến trúc 64 `bit` trên máy tính của tôi. Địa chỉ của mỗi phần tử 
được cách nhau 16 `byte`.

Sự thật là biến `v` có cùng địa chỉ trên mỗi lần lặp củng cố thêm hiểu biết rằng `v` là một biến 
cục bộ kiểu chuỗi chứa một bản sao của mỗi giá trị chuỗi trong lần lặp.

** Bộ nhớ tạm của CPU (CPU Caches)

Có rất nhiều sự khác biệt vật lý giữa các bộ xử lý và thiết kế của chúng. Trong phần này, 
chúng ta sẽ tìm hiểu sơ bộ về các bộ xử lý và các điểm giống nhau giữa chúng. Hiểu biết này sẽ 
cung cấp cho bạn một khái niệm tốt về cách bộ xử lý hoạt động.

Mỗi lõi bên trong bộ xử lý có bộ nhớ tạm (cache) cục bộ riêng của nó (L1 và L2) và một 
bộ nhớ tạm chung (L3) được sử dụng để lưu trữ/truy cập dữ liệu và các chỉ thị. 
Các luồng (thread) phần cứng trong mỗi lõi có thể truy cập vào bộ nhớ tạm L1 và L2 của chúng.
Dữ liệu từ L3 hoặc bộ nhớ chính cần được sao chép vào bộ nhớ tạm L1 hoặc L2 để truy cập.

.image /tour/eng/static/img/a4.png

Tốc độ truy cập dữ liệu trong các bộ nhớ khác nhau thay đổi từ nhanh nhất đến chậm nhất: 
L1 -> L2 -> L3 -> bộ nhớ chính. Theo Scott Meyers nói, "Nếu hiệu suất quan trọng thì tổng dung 
lượng bộ nhớ bạn có chính là tổng dung lượng của bộ nhớ tạm. Bộ nhớ chính chậm đến mức có thể 
nói rằng nó không tồn tại".

Ngày nay, khi nói về hiệu năng là nói về về cách dữ liệu luân chuyển qua phần cứng 
một cách hiệu quả. Nếu mỗi phần dữ liệu mà phần cứng cần (tại bất kỳ thời điểm nào) 
chỉ tồn tại trong bộ nhớ chính, chương trình của chúng ta sẽ chạy chậm hơn so với khi dữ liệu 
đã có sẵn trong bộ nhớ tạm L1 hoặc L2.

    3GHz(3 clock cycles/ns) * 4 instructions per cycle = 12 instructions per ns!

    1 ns ............. 1 ns .............. 12 instructions  (one) 
    1 µs ......... 1,000 ns .......... 12,000 instructions  (thousand)
    1 ms ..... 1,000,000 ns ...... 12,000,000 instructions  (million)
    1 s .. 1,000,000,000 ns .. 12,000,000,000 instructions  (billion)

    Industry Defined Latencies
    L1 cache reference ......................... 0.5 ns ...................  6 ins
    L2 cache reference ........................... 7 ns ................... 84 ins
    Main memory reference ...................... 100 ns ................. 1200 ins

Làm thế nào để chúng ta viết code mà có thể đảm bảo rằng dữ liệu cần thiết để thực thi một 
chỉ thị luôn có mặt trong bộ nhớ tạm L1 hoặc L2? Chúng ta cần viết code có cơ chế lặp với 
bộ đệm trước của bộ xử lý. Bộ đệm trước sẽ cố gắng dự đoán dữ liệu nào cần thiết trước khi các 
chỉ thị yêu cầu dữ liệu được gửi đến để dữ liệu đã có sẵn trong bộ nhớ tạm L1 hoặc L2.

Có nhiều mức độ chi tiết khác nhau của việc truy cập bộ nhớ tùy thuộc vào nơi việc truy cập 
xảy ra. Code của chúng ta có thể đọc/ghi một `byte` của bộ nhớ như là đơn vị nhỏ nhất của 
việc truy cập bộ nhớ. Tuy nhiên, từ góc nhìn của hệ thống bộ nhớ đệm, độ chi tiết là 64 byte. 
Khối bộ nhớ 64 byte này được gọi là một dòng bộ nhớ đệm (cache line).

Bộ đệm trước hoạt động tốt nhất khi các chỉ thị đang được thực thi tạo ra các mẫu truy cập 
dữ liệu từ bộ nhớ có thể dự đoán được. Một cách để tạo ra một mẫu truy cập bộ nhớ có thể 
dự đoán là xây dựng một khối bộ nhớ liên tục và sau đó lặp qua bộ nhớ đó thực hiện một lần 
duyệt tuyến tính với một bước nhảy có thể dự đoán.

Mảng là cấu trúc dữ liệu quan trọng nhất đối với phần cứng vì nó hỗ trợ các mẫu truy cập 
có thể dự đoán. Tuy nhiên, `slice` là cấu trúc dữ liệu quan trọng nhất trong Go. Slice trong Go 
sử dụng một mảng bên dưới.

Một khi chúng ta xây dựng một mảng, mỗi phần tử có khoảng cách bằng nhau so với phần tử 
tiếp theo hoặc trước đó. Khi duyệt qua một mảng, chúng ta bắt đầu đi qua các dòng bộ nhớ đệm 
theo các bước nhảy có thể dự đoán. Bộ đệm trước sẽ nhận ra mẫu truy cập dữ liệu có thể 
dự đoán này và bắt đầu đưa dữ liệu vào bộ xử lý một cách hiệu quả, do đó giảm chi phí truy cập 
dữ liệu.

Hãy tưởng tượng chúng ta có một ma trận vuông lớn của bộ nhớ và một danh sách liên kết các 
nốt khớp với số lượng phần tử trong ma trận. Nếu chúng ta thực hiện một lần duyệt qua 
danh sách liên kết, và sau đó duyệt qua ma trận theo cả hai hướng (cột và dòng), hiệu suất 
của các lần duyệt khác nhau sẽ như thế nào?

    func RowTraverse() int {
        var ctr int
        for row := 0; row < rows; row++ {
            for col := 0; col < cols; col++ {
                if matrix[row][col] == 0xFF {
                    ctr++
                }
            }
        }
        return ctr
    }

Duyệt theo hàng sẽ có hiệu suất tốt nhất vì nó đi qua bộ nhớ, dòng bộ nhớ đệm liên tục 
bằng cách tạo ra một mẫu truy cập dự đoán được. Các dòng bộ nhớ đệm có thể được tải trước và 
sao chép vào bộ nhớ tạm L1 hoặc L2 trước khi dữ liệu được yêu cầu.

    func ColumnTraverse() int {
        var ctr int
        for col := 0; col < cols; col++ {
            for row := 0; row < rows; row++ {
                if matrix[row][col] == 0xFF {
                    ctr++
                }
            }
        }
        return ctr
    }

Duyệt theo cột là tệ nhất vì nó đi qua các ranh giới trang của hệ điều hành trên mỗi lần 
truy cập bộ nhớ. Điều này không gây ra tính dự đoán cho việc truy cập bộ nhớ đệm và trở thành 
bộ nhớ truy cập ngẫu nhiên.

    func LinkedListTraverse() int {
        var ctr int
        d := list
        for d != nil {
            if d.v == 0xFF {
                ctr++
            }
            d = d.p
        }
        return ctr
    }

Danh sách liên kết chậm gấp đôi so với duyệt theo hàng chủ yếu là do có các dòng bộ nhớ đệm 
bị lỗi (cache line miss) nhưng ít lỗi TLB (Translation Lookaside Buffer). Hầu hết các nốt được 
kết nối trong danh sách tồn tại trong cùng một trang của hệ điều hành.

    BenchmarkLinkListTraverse-16    128      28738407 ns/op
    BenchmarkColumnTraverse-16       30     126878630 ns/op
    BenchmarkRowTraverse-16         310      11060883 ns/op

** Bộ đệm tra cứu bản dịch địa chỉ (Translation Lookaside Buffer - TLB)

Mỗi chương trình đang chạy được cung cấp một bản đồ bộ nhớ đầy đủ của bộ nhớ ảo bởi 
hệ điều hành và chương trình đang chạy nghĩ rằng chúng có toàn bộ bộ nhớ vật lý trên máy. 
Tuy nhiên, bộ nhớ vật lý cần được chia sẻ với tất cả các chương trình đang chạy. Hệ điều hành 
chia sẻ bộ nhớ vật lý bằng cách chia bộ nhớ vật lý thành các trang và ánh xạ các trang đến 
bộ nhớ ảo cho bất kỳ chương trình đang chạy nào. Mỗi hệ điều hành có thể quyết định kích thước 
của một trang, nhưng 4k, 8k, 16k là các kích thước hợp lý và phổ biến.

TLB là một bộ nhớ đệm nhỏ bên trong bộ xử lý giúp giảm độ trễ khi dịch một địa chỉ ảo thành 
địa chỉ vật lý trong phạm vi của một trang hệ điều hành và độ lệch bên trong trang. Một lỗi TLB 
có thể gây ra độ trễ lớn vì bây giờ phần cứng phải đợi hệ điều hành quét bảng trang của nó để 
xác định trang đúng cho địa chỉ ảo cần xét. Nếu chương trình đang chạy trên máy ảo 
(ví dụ như trong điện toán đám mây) thì bảng phân trang máy ảo cần được quét trước.

Hãy nhớ lại những gì đã được nói ở trên:

Danh sách liên kết chậm gấp đôi so với duyệt theo hàng chủ yếu là do có các dòng bộ nhớ đệm 
bị lỗi (cache line miss) nhưng ít lỗi TLB (Translation Lookaside Buffer). Hầu hết các nốt 
được kết nối trong danh sách tồn tại trong cùng một trang của hệ điều hành.

Danh sách liên kết nhanh hơn duyệt theo cột nhờ vào việc truy cập TLB. Mặc dù có các lỗi bộ nhớ 
đệm xảy ra, nhưng vì hầu hết bộ nhớ cho một nhóm nốt sẽ nằm trong cùng một trang hệ điều hành,
nên độ trễ TLB không ảnh hưởng đến hiệu suất. Đây là lý do tại sao đối với các chương trình
sử dụng một lượng lớn bộ nhớ, như các ứng dụng dựa trên DNA, bạn có thể muốn sử dụng một
phiên bản phân phối Linux được cấu hình với kích thước trang là một hoặc hai megabyte bộ nhớ. 

Tổng kết lại, thiết kế hướng dữ liệu là quan trọng. Viết một thuật toán hiệu quả phải
xem xét cách truy cập dữ liệu. Hãy nhớ, hiệu suất ngày nay là về cách bạn có thể
đưa dữ liệu vào bộ xử lý một cách hiệu quả.

- [[https://youtu.be/WDIkqP4JbkE?t=1129][CPU Caches and Why You Care (18:50-20:30)]] - Scott Meyers  
- [[https://youtu.be/WDIkqP4JbkE?t=2676][CPU Caches and Why You Care (44:36-45:40)]] - Scott Meyers   
- [[https://youtu.be/jEG4Qyo_4Bc?t=266][Performance Through Cache-Friendliness (4:25-5:48)]] - Damian Gryski  

** Ghi chú về CPU Cache

.html arrays/array_list.html

** Thông tin thêm

*Độ* *trễ* *tiêu* *chuẩn*

    L1 cache reference ......................... 0.5 ns ...................  6 ins
    Branch mispredict ............................ 5 ns ................... 60 ins
    L2 cache reference ........................... 7 ns ................... 84 ins
    Mutex lock/unlock ........................... 25 ns .................. 300 ins
    Main memory reference ...................... 100 ns ................. 1200 ins           
    Compress 1K bytes with Zippy ............. 3,000 ns (3 µs) ........... 36k ins
    Send 2K bytes over 1 Gbps network ....... 20,000 ns (20 µs) ........  240k ins
    SSD random read ........................ 150,000 ns (150 µs) ........ 1.8M ins
    Read 1 MB sequentially from memory ..... 250,000 ns (250 µs) .......... 3M ins
    Round trip within same datacenter ...... 500,000 ns (0.5 ms) .......... 6M ins
    Read 1 MB sequentially from SSD- ..... 1,000,000 ns (1 ms) ........... 12M ins
    Disk seek ........................... 10,000,000 ns (10 ms) ......... 120M ins
    Read 1 MB sequentially from disk .... 20,000,000 ns (20 ms) ......... 240M ins
    Send packet CA->Netherlands->CA .... 150,000,000 ns (150 ms) ........ 1.8B ins

*Độ* *trễ* *của* *bộ* *nhớ* *tạm*

.image /tour/eng/static/img/cache_latencies_graph.png

** Tài liệu đọc thêm (tiếng Anh)

*CPU* *Caches* */* *Memory*

- [[https://www.youtube.com/watch?v=WDIkqP4JbkE][CPU Caches and Why You Care - Video]] - Scott Meyers  
- [[https://www.youtube.com/watch?v=OFgxAFdxYAQ][A Crash Course in Modern Hardware - Video]] - Cliff Click  
- [[http://frankdenneman.nl/2016/07/06/introduction-2016-numa-deep-dive-series/][NUMA Deep Dive Series]] - Frank Denneman    
- [[http://www.aristeia.com/TalkNotes/codedive-CPUCachesHandouts.pdf][CPU Caches and Why You Care - Deck]] - Scott Meyers  
- [[https://www.youtube.com/watch?v=MC1EKLQ2Wmg][Mythbusting Modern Hardware to Gain 'Mechanical Sympathy']] - Martin Thompson  
- [[http://www.akkadia.org/drepper/cpumemory.pdf][What Every Programmer Should Know About Memory]] - Ulrich Drepper  
- [[http://www.extremetech.com/extreme/188776-how-l1-and-l2-cpu-caches-work-and-why-theyre-an-essential-part-of-modern-chips][How CPU Caches Work and Why]] - Joel Hruska  
- [[http://www.lighterra.com/papers/modernmicroprocessors][Modern Microprocessors A 90 Minute Guide]] - Jason Robert Carey Patterson  
- [[http://lwn.net/Articles/252125][Memory part 2: CPU caches]] - Ulrich Drepper  
- [[http://www.gotw.ca/publications/concurrency-ddj.htm][The Free Lunch Is Over]] - Herb Sutter  
- [[https://m.youtube.com/watch?feature=youtu.be&v=QBu2Ae8-8LM][Data Center Computers: Modern Challenges in CPU Design]] - Dick Sites  
- [[https://en.wikipedia.org/wiki/Wirth%27s_law][Wirth's Law]] - Wikipedia  
- [[http://www.drdobbs.com/parallel/eliminate-false-sharing/217500206][Eliminate False Sharing]] - Herb Sutter  
- [[http://www.ilikebigbits.com/2014_04_21_myth_of_ram_1.html][The Myth Of Ram]] - Emil Ernerfeldt  
- [[https://www.infoq.com/presentations/hardware-transactional-memory][Understanding Transaction Hardware Memory]] - Gil Gene  
- [[https://youtu.be/jEG4Qyo_4Bc?t=266][Performance Through Cache-Friendliness (4:25-5:48)]] - Damian Gryski   
- [[https://www.youtube.com/watch?v=2EWejmkKlxs][Going Nowhere Faster]] - Chandler Carruth  

*Data-Oriented* *Design*

- [[https://www.youtube.com/watch?v=rX0ItVEVjHc][Data-Oriented Design and C++]] - Mike Acton  
- [[https://www.youtube.com/watch?v=fHNmRkzxHWs][Efficiency with Algorithms, Performance with Data Structures]] - Chandler Carruth  
- [[https://www.youtube.com/watch?v=LrVi9LHP8Bk][Taming the performance Beast]] - Klaus Iglberger  
- [[http://harmful.cat-v.org/software/OO_programming/_pdf/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf][Pitfalls of OOP]] - Tony Albrecht  
- [[https://www.youtube.com/watch?v=YQs6IC-vgmo][Why you should avoid Linked Lists]] - Bjarne Stroustrup  
- [[http://gamesfromwithin.com/data-oriented-design][Data-Oriented Design (Or Why You Might Be Shooting Yourself in The Foot With OOP)]] - Noel    
- [[https://www.quora.com/Was-object-oriented-programming-a-failure][Was object-oriented programming a failure?]] - Quora  

** Ghi chú

- Nếu chúng ta không hiểu dữ liệu, chúng ta không hiểu vấn đề.
- Nếu chúng ta không hiểu về chi phí giải quyết vấn đề, chúng ta không thể lập luận về vấn đề.
- Nếu chúng ta không hiểu phần cứng, chúng ta không thể lập luận về chi phí giải quyết vấn đề.
- Mảng là cấu trúc dữ liệu có độ dài cố định không thể thay đổi.
- Mảng có độ dài khác nhau được coi là các kiểu dữ liệu khác nhau.
- Bộ nhớ được cấp phát như một khối liên tục.
- Go cung cấp cho bạn quyền kiểm soát về địa chỉ bộ nhớ.

* Bài tập

Sử dụng mẫu như điểm khởi đầu để hoàn thành các bài tập. Đáp án sẽ được cung cấp. 
Nhưng hãy cố tự làm trước khi xem.

** Bài tập 1

Khai báo một mảng gồm 5 chuỗi với mỗi phần tử được khởi tạo với giá trị zero value 
của nó. Khai báo một mảng thứ hai gồm 5 chuỗi và khởi tạo mảng này với các giá trị khác 0. 
Gán mảng thứ hai cho mảng thứ nhất và hiển thị kết quả của mảng đầu tiên. 
Hiển thị giá trị chuỗi và địa chỉ của mỗi phần tử.

.play arrays/baitap1.go
.play arrays/dapan1.go
